from matplotlib import rc
from sklearn.compose import ColumnTransformer
from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, RandomForestRegressor
from sklearn.metrics import accuracy_score, classification_report
from sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, StandardScaler

import folium
import time
import matplotlib.dates as mdates
import matplotlib.pyplot as plt
import matplotlib.ticker as ticker
import numpy as np
import pandas as pd
import plotly.express as px
import plotly.graph_objs as go
import seaborn as sns
import streamlit as st

# Streamlit emoji: https://streamlit-emoji-shortcodes-streamlit-app-gwckff.streamlit.app/
#Streamlit í˜ì´ì§€ ê¸°ë³¸ ì„¤ì • (ë©”ì¸ í˜ì´ì§€ ë„ˆë¹„ ë„“ê²Œ)
st.set_page_config(layout = "wide") 

with st.spinner("ì ì‹œë§Œ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš”..."):
    time.sleep(1)  #ëŒ€ê¸° ì‹œê°„ ì‹œë®¬ë ˆì´ì…˜
st.success("Data Loaded!")

#í•œê¸€ ë° ë§ˆì´ë„ˆìŠ¤ ê¹¨ì§
plt.rcParams['font.family'] = "Malgun Gothic"
plt.rcParams['axes.unicode_minus'] = False

#GitHubì—ì„œ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ê¸° ìœ„í•œ ê¸°ë³¸ ê²½ë¡œ ì„¤ì •
CSV_FILE_PATH = 'https://raw.githubusercontent.com/jjjjunn/YH_project/refs/heads/main/'

#íšŒì› ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
memeber_df = pd.read_csv(CSV_FILE_PATH + 'members_data.csv')

#ì˜¨ë¼ì¸ ì¬í™œìš© ë°ì´í„° ë¡œë“œ í•¨ìˆ˜(Streamlit ìºì‹± ì ìš©)
@st.cache_data
def on_load_data():
    url_on = "https://raw.githubusercontent.com/jjjjunn/YH_project/main/recycling_online.csv"
    df_on = pd.read_csv(url_on, encoding = "UTF8").fillna(0)    #ê²°ì¸¡ì¹˜(NaN)ì„ 0ìœ¼ë¡œ ì±„ì›€
    df_on.replace([np.inf, -np.inf], np.nan, inplace = True)    #ë¬´í•œëŒ€ ê°’ì„ NaNìœ¼ë¡œ ë³€í™˜
    df_on.fillna(0, inplace = True)                             #ë‹¤ì‹œ NaN ê°’ì„ 0ìœ¼ë¡œ ë³€í™˜
    return df_on                                                #ì „ì²˜ë¦¬ëœ ë°ì´í„° ë°˜í™˜

#ì˜¤í”„ë¼ì¸ ì¬í™œìš© ë°ì´í„° ë¡œë“œ í•¨ìˆ˜(Streamlit ìºì‹± ì ìš©)
@st.cache_data
def off_load_data():
    url_off = "https://raw.githubusercontent.com/jjjjunn/YH_project/main/recycling_off.csv"
    df_off = pd.read_csv(url_off, encoding = "UTF8")
    df_off.replace([np.inf, -np.inf], np.nan, inplace = True)     #ë¬´í•œëŒ€ ê°’ì„ NaNìœ¼ë¡œ ë³€í™˜
    df_off.dropna(subset = ["ë‚ ì§œ"], inplace = True)              #ë‹¤ì‹œ NaN ê°’ì„ 0ìœ¼ë¡œ ë³€í™˜
    return df_off                                                 #ì „ì²˜ë¦¬ëœ ë°ì´í„° ë°˜í™˜

#íšŒì› ë°ì´í„° ì»¬ëŸ¼ëª…ì„ í•œê¸€ë¡œ ë³€ê²½(ë°ì´í„°í”„ë ˆì„ ê°€ë…ì„± ê±”ì„ )
print_df = memeber_df.rename(columns = {
     "age": "ë‚˜ì´",
     "gender": "ì„±ë³„",
     "marriage": "í˜¼ì¸ì—¬ë¶€",
     "city": "ë„ì‹œ",
     "channel": "ê°€ì…ê²½ë¡œ",
     "before_ev": "ì°¸ì—¬_ì „",
     "part_ev": "ì°¸ì—¬ì´ë²¤íŠ¸",
     "after_ev": "ì°¸ì—¬_í›„"
})

#ë²”ì£¼í˜• ë°ì´í„° ê°’ ë³€ê²½(ìˆ«ì > ì˜ë¯¸ ìˆëŠ” ë¬¸ìì—´)
print_df['ì„±ë³„'] = print_df['ì„±ë³„'].map({0 : 'ë‚¨ì', 1 : 'ì—¬ì'})
print_df['í˜¼ì¸ì—¬ë¶€'] = print_df['í˜¼ì¸ì—¬ë¶€'].map({0 : 'ë¯¸í˜¼', 1 : 'ê¸°í˜¼'})
#ë„ì‹œ ì½”ë“œ > ë„ì‹œ ì´ë¦„ ë§¤í•‘
print_df['ë„ì‹œ'] = print_df['ë„ì‹œ'].map({
    0 : 'ë¶€ì‚°', 1 : 'ëŒ€êµ¬', 2 : 'ì¸ì²œ', 3 : 'ëŒ€ì „', 
    4 : 'ìš¸ì‚°', 5 : 'ê´‘ì£¼', 6 : 'ì„œìš¸', 7 : 'ê²½ê¸°', 
    8 : 'ê°•ì›', 9 : 'ì¶©ë¶', 10 : 'ì¶©ë‚¨', 11 : 'ì „ë¶', 
    12 : 'ì „ë‚¨', 13 : 'ê²½ë¶', 14 : 'ê²½ë‚¨', 15 : 'ì„¸ì¢…', 16 : 'ì œì£¼'})

#ê°€ì… ê²½ë¡œ ì½”ë“œ > ì˜ë¯¸ ìˆëŠ” ë¬¸ìì—´ ë§¤í•‘
print_df['ê°€ì…ê²½ë¡œ'] = print_df['ê°€ì…ê²½ë¡œ'].map({
    0 : "ì§ì ‘ ìœ ì…", 1 : "í‚¤ì›Œë“œ ê²€ìƒ‰", 2 : "ë¸”ë¡œê·¸", 3 : "ì¹´í˜", 
    4 : "ì´ë©”ì¼", 5 : "ì¹´ì¹´ì˜¤í†¡", 6 : "ë©”íƒ€", 7 : "ì¸ìŠ¤íƒ€ê·¸ë¨", 
    8 : "ìœ íŠœë¸Œ", 9 : "ë°°ë„ˆ ê´‘ê³ ", 10 : "íŠ¸ìœ„í„° X", 11 : "ê¸°íƒ€ SNS"})

#ì°¸ì—¬ ì „ ìƒíƒœ ì½”ë“œ > ë¬¸ìì—´ ë³€í™˜
print_df['ì°¸ì—¬_ì „'] = print_df['ì°¸ì—¬_ì „'].map({0 : 'ê°€ì…', 1 : 'ë¯¸ê°€ì…'})

#ì°¸ì—¬ ì´ë²¤íŠ¸ ì½”ë“œ > ì˜ë¯¸ ìˆëŠ” ì´ë²¤íŠ¸ëª… ë§¤í•‘
print_df['ì°¸ì—¬ì´ë²¤íŠ¸'] = print_df['ì°¸ì—¬ì´ë²¤íŠ¸'].map({
    0 : "ì›Œí¬ìˆ ê°œìµœ", 1 : "ì¬í™œìš© í’ˆëª© ìˆ˜ì§‘ ì´ë²¤íŠ¸", 2 : "ì¬í™œìš© ì•„íŠ¸ ì „ì‹œ",
    3 : "ê²Œì„ ë° í€´ì¦ˆ", 4 : "ì»¤ë®¤ë‹ˆí‹° ì²­ì†Œ í™œë™", 5 : "ì—…ì‚¬ì´í´ë§ ë§ˆì¼“", 6 : "í™ë³´ ë¶€ìŠ¤ ìš´ì˜"})

#ì°¸ì—¬ í›„ ìƒíƒœ ì½”ë“œ > ë¬¸ìì—´ ë³€í™˜
print_df['ì°¸ì—¬_í›„'] = print_df['ì°¸ì—¬_í›„'].map({0 : 'ê°€ì…', 1 : 'ë¯¸ê°€ì…'})

#ì˜¨ë¼ì¸ & ì˜¤í”„ë¼ì¸ ë°ì´í„° ë¡œë“œ
df_on = on_load_data()
df_off = off_load_data()

#íšŒì› ë°ì´í„° ì¤‘ ì¼ë¶€ ì»¬ëŸ¼ ì„ íƒ
data = memeber_df[['age', 'gender', 'marriage', 'after_ev']]

#Streamlit UI êµ¬ì„±
with st.expander('íšŒì› ë°ì´í„°'):
    st.dataframe(print_df, use_container_width = True)      #ë³€í™˜ëœ íšŒì› ë°ì´í„° í‘œì‹œ
with st.expander('ì˜¨ë¼ì¸ ë°ì´í„°'):
    st.dataframe(df_on, use_container_width = True)         #ì˜¨ë¼ì¸ ì¬í™œìš© ë°ì´í„° í‘œì‹œ
with st.expander('ì˜¤í”„ë¼ì¸ ë°ì´í„°'):
    st.dataframe(df_off, use_container_width = True)        #ì˜¤í”„ë¼ì¸ ì¬í™œìš© ë°ì´í„° í‘œì‹œ

#Streamlit íƒ­ì„ ì´ìš©í•œ ë‹¤ì¤‘ í˜ì´ì§€ êµ¬ì„±
tab1, tab2, tab3, tab4, tab5 = st.tabs(['ì„œë¹„ìŠ¤ê°€ì… ì˜ˆì¸¡', 'ì¶”ì²œ ìº í˜ì¸', 'ì¶”ì²œ ì±„ë„', 'ì „í™˜ìœ¨ ì˜ˆì¸¡', 'ë°©ë¬¸ì ìˆ˜ ì˜ˆì¸¡'])

#íƒ­1 : ì„œë¹„ìŠ¤ ê°€ì… ì˜ˆì¸¡ ëª¨ë¸
with tab1: 
    first_column, second_column, thrid_columns = st.columns([6, 2, 2])
    
    #ì²« ë²ˆì§¸ ì—´ : ì—°ë ¹ëŒ€ ì„ íƒ
    with first_column:
        st.write("ì„œë¹„ìŠ¤ê°€ì… ì˜ˆì¸¡ ëª¨ë¸ì…ë‹ˆë‹¤. ì•„ë˜ì˜ ì¡°ê±´ì„ ì„ íƒí•´ ì£¼ì„¸ìš”.")
        #ìŠ¬ë¼ì´ë”ë¡œ ì—°ë ¹ëŒ€ ì„ íƒ (ê¸°ë³¸ê°’ : 35 ~ 45ì„¸)
        ages_1 = st.slider(
            "ì—°ë ¹ëŒ€ë¥¼ ì„ íƒí•´ ì£¼ì„¸ìš”.",
            25, 65, (35, 45)
        )
        st.write(f"**ì„ íƒ ì—°ë ¹ëŒ€: :red[{ages_1}]ì„¸**")
    
    #ë‘ ë²ˆì§¸ ì—´ : ì„±ë³„ ì„ íƒ
    with second_column:
        gender_1 = st.radio(
            "ì„±ë³„ì„ ì„ íƒí•´ ì£¼ì„¸ìš”.",
            ["ë‚¨ì", "ì—¬ì"],
            index=1     #ê¸°ë³¸ê°’ : ì—¬ì
        )
    
    #ì„¸ ë²ˆì§¸ ì—´ : í˜¼ì¸ì—¬ë¶€ ì„ íƒ
    with thrid_columns:
        marriage_1 = st.radio(
            "í˜¼ì¸ì—¬ë¶€ë¥¼ ì„ íƒí•´ ì£¼ì„¸ìš”.",
            ["ë¯¸í˜¼", "ê¸°í˜¼"],
            index=1     #ê¸°ë³¸ê°’ : ê¸°í˜¼
        )
    
    #ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ ë° í‰ê°€ í•¨ìˆ˜
    def service_predict(data):
        #ë°ì´í„° ì „ì²˜ë¦¬ ë° íŒŒì´í”„ë¼ì¸ ì„¤ì •
        numeric_features = ['age']                      #ìˆ˜ì¹˜í˜• í”¼ì²˜
        categorical_features = ['gender', 'marriage']   #ë²”ì£¼í˜• í”¼ì²˜

        preprocessor = ColumnTransformer(
            #ìˆ˜ì¹˜í˜•, ë²”ì£¼í˜• ë°ì´í„° ë³€í™˜ê¸° ì„¤ì •
            transformers = [    
                ('num', StandardScaler(), numeric_features),    #ìˆ˜ì¹˜í˜• : StandardScaler
                ('cat', OneHotEncoder(categories='auto'), categorical_features)                           #ë²”ì£¼í˜• : OneHotEncoder
            ]
        )

        #ëœë¤ í¬ë ˆìŠ¤íŠ¸ ëª¨ë¸
        #íŒŒì´í”„ë¼ì¸ êµ¬ì„±
        model = Pipeline(steps = [
            #ì „ì²˜ë¦¬ê¸°
            ('preprocessor', preprocessor),
            #ë¶„ë¥˜ê¸° : ëœë¤ í¬ë ˆìŠ¤íŠ¸
            ('classifier', RandomForestClassifier(random_state = 42, n_jobs = -1))      #n_jobs = -1ë¡œ ëª¨ë“  ì½”ì–´ ì‚¬ìš©
        ])

        #ë°ì´í„° ë¶„í• (X : íŠ¹ì„±, y : íƒ€ê²Ÿ)
        X = data.drop(columns = ['after_ev'])     #'after_ev'ë¥¼ ì œì™¸í•œ íŠ¹ì„±ë§Œ ì‚¬ìš©
        y = data['after_ev']                      #íƒ€ê²Ÿ ë³€ìˆ˜('after_ev'ê°€ ê°€ì…/ë¯¸ê°€ì… ì—¬ë¶€)
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)       #í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„í• 

        #í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ì„ ìœ„í•œ ê·¸ë¦¬ë“œ ì„œì¹˜
        param_grid = {
            'classifier__n_estimators': [100, 200],     #n_estimators : íŠ¸ë¦¬ ê°œìˆ˜
            'classifier__max_depth': [None, 10, 20],    #max_depth : íŠ¸ë¦¬ ê¹Šì´ 
            'classifier__min_samples_split': [2, 5]     #min_samples_split : ë…¸ë“œ ë¶„í•  ê¸°ì¤€
        }

        #ê·¸ë¦¬ë“œ ì„œì¹˜ ì‹¤í–‰
        grid_search = GridSearchCV(estimator = model, param_grid = param_grid, cv = 3, n_jobs = -1, verbose = 2)
        grid_search.fit(X_train, y_train)       #í•™ìŠµ ìˆ˜í–‰

        #ìµœì ì˜ ëª¨ë¸ë¡œ ì˜ˆì¸¡ ìˆ˜í–‰
        y_pred = grid_search.predict(X_test)

        #ì„±ëŠ¥ í‰ê°€(ì •í™•ë„ ì¶œë ¥)
        accuracy = accuracy_score(y_test, y_pred)   #ì •í™•ë„ ê³„ì‚°
        st.write(f"ì´ ëª¨ë¸ì˜ í…ŒìŠ¤íŠ¸ ì •í™•ë„ëŠ” {accuracy * 100:.1f}% ì…ë‹ˆë‹¤.")

        #ìµœì  ëª¨ë¸ê³¼ íŠ¹ì„± ì¤‘ìš”ë„ ë°˜í™˜
        return grid_search.best_estimator_, grid_search.best_estimator_.named_steps['classifier'].feature_importances_

    #ì‚¬ìš©ìê°€ ì…ë ¥í•œ ê°’ì„ ìƒˆë¡œìš´ ë°ì´í„°ë¡œ ë³€í™˜í•˜ì—¬ ì˜ˆì¸¡ ìˆ˜í–‰
    def pre_result(model, new_data):
        prediction = model.predict(new_data)    #ì˜ˆì¸¡ ìˆ˜í–‰
        st.write(f"**ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼: :rainbow[{'ê°€ì…' if prediction[0] == 0 else 'ë¯¸ê°€ì…'}]**")

    #íŠ¹ì„± ì¤‘ìš”ë„ ì‹œê°í™”
    def plot_feature_importance(importances, feature_names):
        indices = np.argsort(importances)[::-1]     #ì¤‘ìš”ë„ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
        plt.figure(figsize = (2, 1))                #ê·¸ë˜í”„ í¬ê¸° ì„¤ì •
        plt.title("íŠ¹ì„± ì¤‘ìš”ë„")                    #ì œëª©
        plt.barh(range(len(importances)), importances[indices], align = "center")       #ìˆ˜í‰ ë°” ê·¸ë˜í”„
        plt.yticks(range(len(importances)), [feature_names[i] for i in indices])        # íŠ¹ì„± ì´ë¦„ ì¶œë ¥
        plt.xlabel("ì¤‘ìš”ë„")        #xì¶• ë ˆì´ë¸”
        st.pyplot(plt)              #Streamlitì—ì„œ ì‹œê°í™” ì¶œë ¥

    #ì˜ˆì¸¡í•˜ê¸° ë²„íŠ¼ í´ë¦­ì— ë”°ë¥¸ ë™ì‘
    if st.button("ì˜ˆì¸¡í•˜ê¸°"):
        #ê¸°ì¡´ ë°ì´í„°ë¡œ ëª¨ë¸ í•™ìŠµ
        model, feature_importances = service_predict(data)

        #ì…ë ¥ëœ ê°’ì„ ìƒˆë¡œìš´ ë°ì´í„° í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        new_data = pd.DataFrame({
            'age': [(ages_1[0] + ages_1[1]) / 2],           #ë‚˜ì´ì˜ ì¤‘ì•™ê°’
            'gender': [1 if gender_1 == 'ì—¬ì' else 0],     #ì„±ë³„ì„ 1(ì—¬ì), 0(ë‚¨ì)ë¡œ ë³€í™˜
            'marriage': [1 if marriage_1 == 'ê¸°í˜¼' else 0]  #í˜¼ì¸ ì—¬ë¶€ë¥¼ 1(ê¸°í˜¼), 0(ë¯¸í˜¼)ìœ¼ë¡œ ë³€í™˜
        })

        #ì˜ˆì¸¡ ìˆ˜í–‰ ë° ê²°ê³¼ ì¶œë ¥
        pre_result(model, new_data)

        #íŠ¹ì„± ì¤‘ìš”ë„ ì‹œê°í™”
        feature_names = ['age'] + list(model.named_steps['preprocessor'].transformers_[1][1].get_feature_names_out())       #íŠ¹ì„± ì´ë¦„ ë¦¬ìŠ¤íŠ¸
        plot_feature_importance(feature_importances, feature_names)                                                         #ì¤‘ìš”ë„ ì‹œê°í™”

#ë‘ ë²ˆì§¸ ë°ì´í„°ì…‹(ì°¸ì—¬ ì´ë²¤íŠ¸ ë° í›„ì† ê°€ì… ì—¬ë¶€ í¬í•¨)
data_2 = memeber_df[['age', 'gender', 'marriage', 'part_ev', 'after_ev']]   #ì¶”ê°€ëœ 'part_ev' (ì°¸ì—¬ ì´ë²¤íŠ¸)

#ì°¸ì—¬ ì´ë²¤íŠ¸ë¥¼ ìœ„í•œ ë§¤í•‘ì •ì˜
event_mapping = {
    0: "ì›Œí¬ìˆ ê°œìµœ",
    1: "ì¬í™œìš© í’ˆëª© ìˆ˜ì§‘ ì´ë²¤íŠ¸",
    2: "ì¬í™œìš© ì•„íŠ¸ ì „ì‹œ",
    3: "ê²Œì„ ë° í€´ì¦ˆ",
    4: "ì»¤ë®¤ë‹ˆí‹° ì²­ì†Œ í™œë™",
    5: "ì—…ì‚¬ì´í´ë§ ë§ˆì¼“",
    6: "í™ë³´ ë¶€ìŠ¤ ìš´ì˜"
}

#íƒ­2 : ìº í˜ì¸ ì¶”ì²œ ëª¨ë¸
with tab2: 
    #3ê°œì˜ ì—´ë¡œ ë¶„í• 
    first_column, second_column, thrid_columns = st.columns([6, 2, 2]) 
    #ì²« ë²ˆì§¸ ì—´ : ì—°ë ¹ëŒ€ ì„ íƒ
    with first_column:
        st.write("ìº í˜ì¸ ì¶”ì²œ ëª¨ë¸ì…ë‹ˆë‹¤. ì•„ë˜ì˜ ì¡°ê±´ì„ ì„ íƒí•´ ì£¼ì„¸ìš”.")
        #ìŠ¬ë¼ì´ë”ë¡œ ì—°ë ¹ëŒ€ ì„ íƒ(ê¸°ë³¸ê°’ 35 ~ 45ì„¸)
        ages_2 = st.slider(
            "ì—°ë ¹ëŒ€ë¥¼ ì„ íƒí•´ ì£¼ì„¸ìš”.",
            25, 65, (35, 45),
            key = 'slider_2'  #ìŠ¬ë¼ì´ë”ì˜ ê³ ìœ  í‚¤
        )
        st.write(f"**ì„ íƒ ì—°ë ¹ëŒ€: :red[{ages_2}]ì„¸**")
    #ë‘ ë²ˆì§¸ ì—´ : ì„±ë³„ ì„ íƒ
    with second_column:
        gender_2 = st.radio(
            "ì„±ë³„ì„ ì„ íƒí•´ ì£¼ì„¸ìš”.",
            ["ë‚¨ì", "ì—¬ì"],
            index = 1,          #ê¸°ë³¸ê°’ : ì—¬ì
            key = 'radio2_1'    #ë¼ë””ì˜¤ ë²„íŠ¼ì˜ ê³ ìœ  í‚¤
        )
    #ì„¸ ë²ˆì§¸ ì—´ : í˜¼ì¸ì—¬ë¶€ ì„ íƒ
    with thrid_columns:
        marriage_2 = st.radio(
            "í˜¼ì¸ì—¬ë¶€ë¥¼ ì„ íƒí•´ ì£¼ì„¸ìš”.",
            ["ë¯¸í˜¼", "ê¸°í˜¼"],
            index = 1,          #ê¸°ë³¸ê°’ : ê¸°í˜¼
            key = 'radio2_2'    #ë¼ë””ì˜¤ ë²„íŠ¼ì˜ ê³ ìœ  í‚¤
        )

    #ìº í˜ì¸ ì¶”ì²œ ëª¨ë¸ í•¨ìˆ˜ ì •ì˜
    def recommend_event(data_2):
        #íŠ¹ì„±ê³¼ íƒ€ê²Ÿ ë°ì´í„° ì„¤ì •(ì—¬ê¸°ì„œëŠ” 'age', 'gender', 'marriage', 'part_ev' ì‚¬ìš©)
        X = data_2[['age', 'gender', 'marriage', 'part_ev']]
        y = data_2['after_ev']      #'after_ev'ë¥¼ íƒ€ê²Ÿ ë³€ìˆ˜ë¡œ ì„¤ì •

        #ì°¸ì—¬ ì´ë²¤íŠ¸ ì»¬ëŸ¼ì— ëŒ€í•´ ë”ë¯¸ ë³€ìˆ˜ ìƒì„± (OneHotEncoding)
        X = pd.get_dummies(X, columns = ['part_ev'], drop_first = True)     #ì²« ë²ˆì§¸ ì»¬ëŸ¼ì„ ì œê±°í•˜ì—¬ ë‹¤ì¤‘ê³µì„ ì„± ë°©ì§€

        #ë°ì´í„° ë¶„í• (í›ˆë ¨ ë°ì´í„° : 80%, í…ŒìŠ¤íŠ¸ ë°ì´í„° : 20%)
        X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.2, random_state=42)

        #ëœë¤ í¬ë ˆìŠ¤íŠ¸ ëª¨ë¸ ì •ì˜ ë° í•™ìŠµ
        model = RandomForestClassifier(random_state=42)
        model.fit(X_train, y_train)     #ëª¨ë¸ í•™ìŠµ

        return model, X_train.columns  #ëª¨ë¸ê³¼ í”¼ì³ ì´ë¦„ì„ ë°˜í™˜

    #ì‚¬ìš©ì ì…ë ¥ì„ í†µí•œ ìº í˜ì¸ ì¶”ì²œ í‰ê°€
    if st.button("íš¨ê³¼ì ì¸ ì´ë²¤íŠ¸ ì¶”ì²œë°›ê¸°"):
        #ìº í˜ì¸ ì¶”ì²œ ëª¨ë¸ í›ˆë ¨
        model, feature_names = recommend_event(data_2)

        event_results = {}

        #ê° ì´ë²¤íŠ¸ì— ëŒ€í•œ ì¶”ì²œ ê°€ëŠ¥ì„± í‰ê°€ (0ë¶€í„° 6ê¹Œì§€ ì´ë²¤íŠ¸ì— ëŒ€í•´ ë°˜ë³µ)
        for event in range(7):  #part_evê°€ 0ë¶€í„° 6ê¹Œì§€ì˜ ìˆ«ìì— í•´ë‹¹í•˜ëŠ” ì´ë²¤íŠ¸
            #ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì •ë³´ë¡œ ìƒˆë¡œìš´ ë°ì´í„° ìƒì„±
            new_user_data = pd.DataFrame({
                'age': [(ages_2[0] + ages_2[1]) / 2],               #ì—°ë ¹ëŒ€ì˜ ì¤‘ì•™ê°’ ê³„ì‚°
                'gender': [1 if gender_2 == 'ì—¬ì' else 0],         #ì„±ë³„ì„ 1(ì—¬ì), 0(ë‚¨ì)ë¡œ ë³€í™˜
                'marriage': [1 if marriage_2 == 'ê¸°í˜¼' else 0],     #í˜¼ì¸ ì—¬ë¶€ë¥¼ 1(ê¸°í˜¼), )ë¯¸í˜¼)ìœ¼ë¡œ ë³€í™˜
                'part_ev': [event]                                  #ì°¸ì—¬ ì´ë²¤íŠ¸ ë²ˆí˜¸ë¡œ ì§€ì •
            })

            #ë”ë¯¸ ë³€ìˆ˜ ìƒì„±(ì…ë ¥ ë°ì´í„°ì—ë„ 'part_ev'ì— ëŒ€í•œ ì¸ì½”ë”© ìˆ˜í–‰)
            new_user_data = pd.get_dummies(new_user_data, columns = ['part_ev'], drop_first = True)

            #ê¸°ë³¸ í”¼ì³ì™€ ì¼ì¹˜í•˜ë„ë¡ ì •ë ¬
            new_user_data = new_user_data.reindex(columns = feature_names, fill_value = 0)

            #ì˜ˆì¸¡ ìˆ˜í–‰
            prediction = model.predict(new_user_data)
            event_results[event] = prediction[0]    #ê°€ì… ì—¬ë¶€ ì €ì¥(0 : ê°€ì…, 1 : ë¯¸ê°€ì…)

        #ê°€ì…(0) ê°€ëŠ¥ì„±ì´ ë†’ì€ ì´ë²¤íŠ¸ ì¤‘ ê°€ì¥ ë†’ì€ ê²ƒ ì„ íƒ
        possible_events = {event: result for event, result in event_results.items() if result == 0} 

        #ê°€ì… ê°€ëŠ¥ì„±ì´ ë†’ì€ ì´ë²¤íŠ¸ê°€ ìˆì„ ê²½ìš°ê°€ì¥ íš¨ê³¼ì ì¸ ì´ë²¤íŠ¸ ì¶”ì²œ
        if possible_events:
            best_event = max(possible_events, key = possible_events.get)
            st.write(f"**ì¶”ì²œ ì´ë²¤íŠ¸: :violet[{event_mapping[best_event]}] ğŸ‘ˆ ì´ë²¤íŠ¸ê°€ ê°€ì¥ íš¨ê³¼ì ì…ë‹ˆë‹¤!**")
        else:
            #ê°€ì… ê°€ëŠ¥ì„±ì´ ë†’ì€ ì´ë²¤íŠ¸ê°€ ì—†ìœ¼ë©´ ë‹¤ë¥¸ ìº í˜ì¸ ì¶”ì²œ
            st.write("ì¶”ì²œ ì´ë²¤íŠ¸: ê°€ì… í™•ë¥ ì´ ë†’ì§€ ì•Šìœ¼ë¯€ë¡œ ë‹¤ë¥¸ ìº í˜ì¸ì„ ê³ ë ¤í•´ë³´ì„¸ìš”.")

#ë°ì´í„°ì…‹ì— ëŒ€í•œ ì¶”ê°€ ì •ë³´(ìœ ì…ê²½ë¡œ)
data_3 = memeber_df[['age', 'gender', 'marriage', 'channel', 'after_ev']]   #ìœ ì…ê²½ë¡œ(channel) ì¶”ê°€ëœ ë°ì´í„°

#ê°€ì… ì‹œ ìœ ì…ê²½ë¡œ ë§¤í•‘ ì •ì˜ (ê° ìˆ«ìì— í•´ë‹¹í•˜ëŠ” ìœ ì…ê²½ë¡œë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜)
register_channel = {
    0:"ì§ì ‘ ìœ ì…",
    1:"í‚¤ì›Œë“œ ê²€ìƒ‰",
    2:"ë¸”ë¡œê·¸",
    3:"ì¹´í˜",
    4:"ì´ë©”ì¼",
    5:"ì¹´ì¹´ì˜¤í†¡",
    6:"ë©”íƒ€",
    7:"ì¸ìŠ¤íƒ€ê·¸ë¨",
    8:"ìœ íŠœë¸Œ", 
    9:"ë°°ë„ˆ ê´‘ê³ ", 
    10:"íŠ¸ìœ„í„° X", 
    11:"ê¸°íƒ€ SNS"
}

#íƒ­3 : ë§ˆì¼€íŒ… ì±„ë„ ì¶”ì²œ ëª¨ë¸
with tab3: 
    #3ê°œì˜ ì—´ë¡œ ë¶„í• 
    col1, col2, col3 = st.columns([6, 2, 2])
    #ì²« ë²ˆì§¸ ì—´ : ì—°ë ¹ëŒ€ ì„ íƒ
    with col1:
        st.write("ë§ˆì¼€íŒ… ì±„ë„ ì¶”ì²œ ëª¨ë¸ì…ë‹ˆë‹¤. ì•„ë˜ì˜ ì¡°ê±´ì„ ì„ íƒí•´ ì£¼ì„¸ìš”")
        #ìŠ¬ë¼ì´ë”ë¡œ ì—°ë ¹ëŒ€ ì„ íƒ(ê¸°ë³¸ê°’ : 35 ~ 45ì„¸)
        ages_3 = st.slider(
            "ì—°ë ¹ëŒ€ë¥¼ ì„ íƒí•´ ì£¼ì„¸ìš”.",
            25, 65, (35, 45),
            key = 'slider_3'      #ìŠ¬ë¼ì´ë”ì˜ ê³ ìœ  í‚¤
        )
        st.write(f"**ì„ íƒ ì—°ë ¹ëŒ€: :red[{ages_3}]ì„¸**")
    
    #ë‘ ë²ˆì§¸ ì—´ : ì„±ë³„ ì„ íƒ
    with col2:
        gender_3 = st.radio(
            "ì„±ë³„ì„ ì„ íƒí•´ ì£¼ì„¸ìš”.",
            ["ë‚¨ì", "ì—¬ì"],
            index = 1,          #ê¸°ë³¸ê°’ : ê¸°í˜¼
            key = 'radio3_1'    #ë¼ë””ì˜¤ ë²„íŠ¼ì˜ ê³ ìœ  í‚¤
        )
    
    #ì„¸ ë²ˆì§¸ ì—´ : í˜¼ì¸ì—¬ë¶€ ì„ íƒ
    with col3:
        marriage_3 = st.radio(
            "í˜¼ì¸ì—¬ë¶€ë¥¼ ì„ íƒí•´ ì£¼ì„¸ìš”.",
            ["ë¯¸í˜¼", "ê¸°í˜¼"],
            index = 1,          #ê¸°ë³¸ê°’ : ê¸°í˜¼
            key = 'radio3_2'    #ë¼ë””ì˜¤ ë²„íŠ¼ì˜ ê³ ìœ  í‚¤
        )

    #ë§ˆì¼€íŒ… ì±„ë„ ì¶”ì²œ ëª¨ë¸ í•¨ìˆ˜ ì •ì˜
    def recommend_channel(data_3):
        #íŠ¹ì„±ê³¼ íƒ€ì¼“ ë°ì´í„° ì„¤ì •('age', 'gender', 'marriage', 'channel' ì‚¬ìš©)
        X = data_3[['age', 'gender', 'marriage', 'channel']]
        y = data_3['after_ev']

        #ìœ ì… ì±„ë„ì„ ë²”ì£¼í˜• ë³€ìˆ˜ë¡œ ë³€í™˜(OneHotEncoding)
        X = pd.get_dummies(X, columns = ['channel'], drop_first = True)

        #ë°ì´í„° ë¶„í• 
        X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.2, random_state = 42)

        #ëœë¤ í¬ë ˆìŠ¤íŠ¸ ëª¨ë¸ ì •ì˜ ë° í•™ìŠµ
        model = RandomForestClassifier(random_state = 42)
        model.fit(X_train, y_train)     #ëª¨ë¸ í•™ìŠµ

        #í•™ìŠµëœ ëª¨ë¸ê³¼ í”¼ì³ ì´ë¦„ ë°˜í™˜
        return model, X_train.columns  

    #ì‚¬ìš©ì ì •ë³´ ì…ë ¥ì„ í†µí•œ ë§ˆì¼€íŒ… ì¶”ì²œ í‰ê°€
    if st.button("íš¨ê³¼ì ì¸ ë§ˆì¼€íŒ… ì±„ë„ ì¶”ì²œë°›ê¸°"):
        #ë§ˆì¼€íŒ… ì±„ë„ ì¶”ì²œ ëª¨ë¸ í›ˆë ¨
        model, feature_names = recommend_channel(data_3)

        channel_results = {}

        #ê° ì±„ë„ì— ëŒ€í•œ ì¶”ì²œ ê°€ëŠ¥ì„± í‰ê°€ (ì´ 12ê°œì˜ ì±„ë„)
        for channel in range(12):   #ìœ ì… ê²½ë¡œê°€ 0ë¶€í„° 11ê¹Œì§€ì˜ ìˆ«ìë¡œ í‘œí˜„ë¨
            if channel in (0,1):    #ì§ì  ìœ ì…(0)ê³¼ í‚¤ì›Œë“œ ê²€ìƒ‰(11)ì€ ì œì™¸(ë¹„íš¨ìœ¨ì ì¼ ê°€ëŠ¥ì„±ì´ ë†’ìŒ)
                continue

            #ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì •ë³´ë¡œ ìƒˆë¡œìš´ ë°ì´í„° ìƒì„±
            new_user_data = pd.DataFrame({
                'age': [(ages_2[0] + ages_2[1]) / 2],               #ì—°ë ¹ëŒ€ì˜ ì¤‘ì•™ê°’ ê³„ì‚°
                'gender': [1 if gender_2 == 'ì—¬ì' else 0],         #ì„±ë³„ì„ 1(ì—¬ì), 0(ë‚¨ì)ë¡œ ë³€í™˜
                'marriage': [1 if marriage_2 == 'ê¸°í˜¼' else 0],     #í˜¼ì¸ ì—¬ë¶€ë¥¼ 1(ê¸°í˜¼), 0(ë¯¸í˜¼)ìœ¼ë¡œ ë³€í™˜
                'channel': [channel]                                #ë²ˆí˜¸ë¡œ ë§¤í•‘ëœ ìœ ì… ì±„ë„
            })

            #ë”ë¯¸ ë³€ìˆ˜ ìƒì„±(ì…ë ¥ ë°ì´í„°ì—ë„ 'channel'ì— ëŒ€í•œ ì¸ì½”ë”© ìˆ˜í–‰)
            new_user_data = pd.get_dummies(new_user_data, columns = ['channel'], drop_first = True)

            #ê¸°ì¡´ í”¼ì³ì™€ ì¼ì¹˜í•˜ë„ë¡ ì •ë ¬
            new_user_data = new_user_data.reindex(columns = feature_names, fill_value = 0)

            #ì˜ˆì¸¡ ìˆ˜í–‰
            prediction = model.predict(new_user_data)
            channel_results[channel] = prediction[0]    #ê°€ì… ì—¬ë¶€ ì €ì¥ (0 : ê°€ì…, 1 : ë¯¸ê°€ì…)

        #ê°€ì…(0) ê°€ëŠ¥ì„±ì´ ë†’ì€ ì±„ë„ë§Œ í•„í„°ë§
        possible_channels = {channel: result for channel, result in channel_results.items() if result == 0} 

        #ì¶”ì²œí•  ì±„ë„ì´ ìˆì„ ê²½ìš°, ê°€ì… ê°€ëŠ¥ì„±ì´ ë†’ì€ ìƒìœ„ 3ê°œ ì±„ë„ ì¶”ì²œ
        if possible_channels:
            best_channels = sorted(possible_channels.keys(), key = lambda x: possible_channels[x])[:3]      #ê°€ì¥ ì¢‹ì€ 3ê°œ ì±„ë„ ì„ íƒ
            recommended_channels = [register_channel[ch] for ch in best_channels]                           #ì±„ë„ ë²ˆí˜¸ë¥¼ ì´ë¦„ìœ¼ë¡œ ë³€í™˜
            st.write(f"**ì¶”ì²œ ë§ˆì¼€íŒ… ì±„ë„:** :violet[{', '.join(recommended_channels)}] ğŸ‘ˆ ì´ ì±„ë„ë“¤ì´ ê°€ì¥ íš¨ê³¼ì ì…ë‹ˆë‹¤!")
        else:
            #ê°€ì… ê°€ëŠ¥ì„±ì´ ë†’ì€ ì±„ë„ì´ ì—†ìœ¼ë©´ ë‹¤ë¥¸ ì±„ë„ ê³ ë ¤ ê¶Œì¥
            st.write("ì¶”ì²œ ë§ˆì¼€íŒ… ì±„ë„: ê°€ì… í™•ë¥ ì´ ë†’ì§€ ì•Šìœ¼ë¯€ë¡œ ë‹¤ë¥¸ ì±„ë„ì„ ê³ ë ¤í•´ë³´ì„¸ìš”.")

#íƒ­4 : ì˜¨ë¼ì¸ ì „í™˜ìœ¨ ì˜ˆì¸¡ ëª¨ë¸
with tab4:  
    #ì‚¬ìš©ì ì…ë ¥ì„ ìœ„í•œ ì²´í¬ë°•ìŠ¤ ì„¤ì •
    select_all_device = st.checkbox("ë””ë°”ì´ìŠ¤ ì „ì²´ ì„ íƒ")   #ëª¨ë“  ë””ë°”ì´ìŠ¤ ì„ íƒ ì—¬ë¶€ í™•ì¸
    device_options = df_on["ë””ë°”ì´ìŠ¤"].unique().tolist()    #ì‚¬ìš© ê°€ëŠ¥í•œ ë””ë°”ì´ìŠ¤ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    select_all_path = st.checkbox("ìœ ì…ê²½ë¡œ ì „ì²´ ì„ íƒ")     #ëª¨ë“  ìœ ì…ê²½ë¡œ ì„ íƒ ì—¬ë¶€ í™•ì¸
    path_options = df_on["ìœ ì…ê²½ë¡œ"].unique().tolist()      #ì‚¬ìš© ê°€ëŠ¥í•œ ìœ ì…ê²½ë¡œ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°

    #ì‚¬ìš©ìê°€ ì „ì²´ ì„ íƒí•˜ë©´ ëª¨ë“  ì˜µì…˜ì„ ì„ íƒí•˜ë„ë¡ ì„¤ì •
    if select_all_device:
        select_device = st.multiselect("ë””ë°”ì´ìŠ¤", device_options, default = device_options)        
    else:
        select_device = st.multiselect("ë””ë°”ì´ìŠ¤", device_options)

    if select_all_path:
        select_path = st.multiselect("ìœ ì…ê²½ë¡œ", path_options, default = path_options)
    else:
        select_path = st.multiselect("ìœ ì…ê²½ë¡œ", path_options)

    #ì‚¬ìš©ìê°€ ì²´ë¥˜ ì‹œê°„ì„ ìŠ¬ë¼ì´ë”ë¡œ ì„ íƒ(ìµœì†Œ : 0ë¶„, ìµœëŒ€ : 100ë¶„, ê¸°ë³¸ê°’ : 0)
    time_input = st.slider("ì²´ë¥˜ ì‹œê°„(ë¶„)", min_value = 0, max_value = 100, value = 0, step = 5)
        
    #ì˜¨ë¼ì¸ ë°ì´í„° ë³µì‚¬ ë° ì›-í•« ì¸ì½”ë”© ì ìš©
    df_ml_on = df_on.copy()
    df_ml_on = pd.get_dummies(df_ml_on, columns = ["ë””ë°”ì´ìŠ¤", "ìœ ì…ê²½ë¡œ"])     #ë””ë°”ì´ìŠ¤ì™€ ìœ ì…ê²½ë¡œë¥¼ ì›-í•« ì¸ì½”ë”©
    
    #ì˜ˆì¸¡ ëª¨ë¸ì— ì‚¬ìš©í•  íŠ¹ì„±ê³¼ íƒ€ì¼“ ë³€ìˆ˜ ì„¤ì •
    features = ["ì²´ë¥˜ì‹œê°„(min)"] + [col for col in df_ml_on.columns if "ë””ë°”ì´ìŠ¤_" in col or "ìœ ì…ê²½ë¡œ_" in col]
    target = "ì „í™˜ìœ¨(ê°€ì…)"

    #ì˜¨ë¼ì¸ ì „í™˜ìœ¨ ì˜ˆì¸¡ ë²„íŠ¼ í´ë¦­ ì‹œ ë™ì‘
    if st.button("ì˜¨ë¼ì¸ ì „í™˜ìœ¨ ì˜ˆì¸¡"):
        #ì…ë ¥(X), ì¶œë ¥(y) ë°ì´í„° ì •ì˜
        X = df_ml_on[features]      #ë…ë¦½ ë³€ìˆ˜
        y = df_ml_on[target]        #ì¢…ì† ë³€ìˆ˜(ì „í™˜ìœ¨)

        #ë°ì´í„° ë¶„í• (í•™ìŠµ ë°ì´í„° : 80%, í…ŒìŠ¤íŠ¸ ë°ì´í„° : 20%)
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)

        #ê²°ì¸¡ê°’ ì²˜ë¦¬(ì¤‘ì•™ê°’ìœ¼ë¡œ ëŒ€ì²´)
        y_train.fillna(y_train.median(), inplace = True)

        #MinMaxScalerë¡œ ì „í™˜ìœ¨ ì •ê·œí™”(0 ~ 1 ë²”ìœ„ë¡œ ë³€í™˜)
        scaler = MinMaxScaler(feature_range = (0, 1))
        y_train_scaled = scaler.fit_transform(y_train.values.reshape(-1, 1))

        #ëœë¤ í¬ë ˆìŠ¤íŠ¸ íšŒê·€ ëª¨ë¸ ìƒì„± ë° í•™ìŠµ
        on_model = RandomForestRegressor(
            n_estimators = 100,         #íŠ¸ë¦¬ ê°œìˆ˜
            max_depth = 10,             #ìµœëŒ€ ê¹Šì´
            min_samples_leaf = 5,       #ë¦¬í”„ ë…¸ë“œì˜ ìµœì†Œ ìƒ˜í”Œ ê°œìˆ˜
            random_state = 42,          
            n_jobs=-1                   #ë³‘ë ¬ ì²˜ë¦¬ í™œì„±í™”
            )                  
        #ëª¨ë¸ í•™ìŠµ
        on_model.fit(X_train, y_train_scaled.ravel())

        #í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡ ë° ìŠ¤ì¼€ì¼ ë³µì›
        y_pred_scaled = on_model.predict(X_test)    #ì˜ˆì¸¡ê°’(ì •ê·œí™”ëœ ê°’)
        y_pred = scaler.inverse_transform(y_pred_scaled.reshape(-1, 1)).flatten()   #ì›ë˜ ê°’ìœ¼ë¡œ ë³€í™˜

        #ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”(ì‹¤ì œ ì „í™˜ìœ¨ VS ì˜ˆì¸¡ ì „í™˜ìœ¨ ë¹„êµ)
        fig_ml_on, ax_ml_on = plt.subplots(figsize = (9, 6))
        sns.lineplot(
            x = y_test,         #ì‹¤ì œ ê°’
            y = y_pred,         #ì˜ˆì¸¡ ê°’
            marker = "o",
            ax = ax_ml_on,
            linestyle = "-",
            label = "ì˜ˆì¸¡ vs ì‹¤ì œ",
            errorbar = None    
        )
        ax_ml_on.grid(visible = True, linestyle = "-", linewidth = 0.5)
        ax_ml_on.set_title("ì „í™˜ìœ¨ ì˜ˆì¸¡ ê²°ê³¼ ë¹„êµ")
        ax_ml_on.set_xlabel("ì‹¤ì œ ì „í™˜ìœ¨")
        ax_ml_on.set_ylabel("ì˜ˆì¸¡ ì „í™˜ìœ¨")
        ax_ml_on.legend()
        st.pyplot(fig_ml_on)
    
        #ì‚¬ìš©ìê°€ ì…ë ¥í•œ ê°’ì„ ê¸°ë°˜ìœ¼ë¡œ ì „í™˜ìœ¨ ì˜ˆì¸¡
        input_data = pd.DataFrame(np.zeros((1, len(features))), columns = features)     #ì…ë ¥ ë°ì´í„°ë¥¼ 0ìœ¼ë¡œ ì´ˆê¸°í™”
        input_data["ì²´ë¥˜ì‹œê°„(min)"] = time_input    #ì‚¬ìš©ìê°€ ì„ íƒí•œ ì²´ë¥˜ ì‹œê°„ ì…ë ¥

        #ì„ íƒëœ ë””ë°”ì´ìŠ¤ ë° ìœ ì… ê²½ë¡œì— ëŒ€í•œ ì›-í•« ì¸ì½”ë”© ì ìš©
        for device in select_device:
            if f"ë””ë°”ì´ìŠ¤_{device}" in input_data.columns:
                input_data[f"ë””ë°”ì´ìŠ¤_{device}"] = 1        #í•´ë‹¹ ë””ë°”ì´ìŠ¤ í™œì„±í™”

        for path in select_path:
            if f"ìœ ì…ê²½ë¡œ_{path}" in input_data.columns:
                input_data[f"ìœ ì…ê²½ë¡œ_{path}"] = 1          #í•´ë‹¹ ìœ ì…ê²½ë¡œ í™œì„±í™”

        #ì „í™˜ìœ¨ ì˜ˆì¸¡ ìˆ˜í–‰ ë° ê°’ ë²”ìœ„ ì œí•œ
        predicted_conversion_scaled = on_model.predict(input_data)[0]   #ì˜ˆì¸¡ê°’(ì •ê·œí™”ëœ ê°’)
        predicted_conversion = scaler.inverse_transform([[predicted_conversion_scaled]])[0, 0]      #ì›ë˜ ê°’ìœ¼ë¡œ ë³€í™˜
        predicted_conversion = np.clip(predicted_conversion, 0, 100)    #0 ~ 100% ë²”ìœ„ ì œí•œ

        #ì˜ˆì¸¡ ê²°ê³¼ ì¶œë ¥
        st.subheader(f"ì˜ˆìƒ ì „í™˜ìœ¨ : {predicted_conversion:.2f}%")

#íƒ­5 : ì˜¤í”„ë¼ì¸ ë°©ë¬¸ì ìˆ˜ ì˜ˆì¸¡
with tab5:  
    #ì˜¤í”„ë¼ì¸ ë°ì´í„° ì¤€ë¹„ : ë‚ ì§œì™€ ì§€ì—­ë³„ ë°©ë¬¸ì ìˆ˜ í•©ì‚°
    df_ml_off = df_off.groupby(["ë‚ ì§œ", "ì§€ì—­"])["ë°©ë¬¸ììˆ˜"].sum().reset_index()    #ë‚ ì§œ ì§€ì—­ë³„ ë°©ë¬¸ì ìˆ˜ ì§‘ê³„
    df_ml_off["ë‚ ì§œ"] = pd.to_datetime(df_ml_off["ë‚ ì§œ"])       #ë‚ ì§œ í˜•ì‹ìœ¼ë¡œ ì „í™˜(datetime í˜•ì‹)
    df_ml_off["year"] = df_ml_off["ë‚ ì§œ"].dt.year               #ì—°ë„ ì •ë³´ ì¶”ì¶œ
    df_ml_off["month"] = df_ml_off["ë‚ ì§œ"].dt.month             #ì›” ì •ë³´ ì¶”ì¶œ
    df_ml_off["day"] = df_ml_off["ë‚ ì§œ"].dt.day                 #ì¼ ì •ë³´ ì¶”ì¶œ
    df_ml_off["day_of_week"] = df_ml_off["ë‚ ì§œ"].dt.weekday     #ìš”ì¼ ì •ë³´ ì¶”ì¶œ(0 = ì›”ìš”ì¼, 6 = ì¼ìš”ì¼)

    #ì§€ì—­ ì„ íƒ ì˜µì…˜ ì¶”ê°€
    select_region = st.selectbox("ì§€ì—­ì„ ì„ íƒí•˜ì„¸ìš”.", df_ml_off["ì§€ì—­"].unique())

    #ì‚¬ìš©ìê°€ ì„ íƒí•œ ì§€ì—­ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„° í•„í„°ë§
    df_region = df_ml_off[df_ml_off["ì§€ì—­"] == select_region]

    #ì˜ˆì¸¡ ëª¨ë¸ì— ì‚¬ìš©í•  ì…ë ¥(feature) ë° ì¶œë ¥(target)ë³€ìˆ˜ ì„¤ì •
    features = ["year", "month", "day", "day_of_week"]      #ì˜ˆì¸¡ ëª¨ë¸ì˜ ë…ë¦½ ë³€ìˆ˜
    X = df_region[features]         #ì…ë ¥ ë°ì´í„°
    y = df_region["ë°©ë¬¸ììˆ˜"]       #ì¶œë ¥ ë°ì´í„°(ë°©ë¬¸ì ìˆ˜)

    #ì˜¤í”„ì•„ë¦° ë°©ë¬¸ì ìˆ˜ ì˜ˆì¸¡ ë²„íŠ¼ í´ë¦­ ì‹œ ì‹¤í–‰
    if st.button("ì˜¤í”„ë¼ì¸ ë°©ë¬¸ì ìˆ˜ ì˜ˆì¸¡"):  
        #ë°ì´í„° ë¶„í• (í•™ìŠµ ë°ì´í„° : 80%, í…ŒìŠ¤íŠ¸ ë°ì´í„° : 20%)
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)
        
        #ëœë¤ í¬ë ˆìŠ¤íŠ¸ íšŒê·€ ëª¨ë¸ ìƒì„± ë° í•™ìŠµ
        off_model = RandomForestRegressor(
            n_estimators = 100,     #íŠ¸ë¦¬ ê°œìˆ˜
            random_state = 42, 
            n_jobs = -1             #ë³‘ë ¬ ì²˜ë¦¬ í™œì„±í™”
            )  
        
        #ëª¨ë¸ í•™ìŠµ
        off_model.fit(X_train, y_train)

        #í–¥í›„ 12ê°œì›”ì˜ ë‚ ì§œ ìƒì„±
        #ë§¤ì›” ë§ˆì§€ë§‰ ë‚ ì§œ ê¸°ì¤€ ìƒì„±
        future_dates = pd.date_range(start = df_region["ë‚ ì§œ"].max(), periods = 12, freq = "ME")
        future_df = pd.DataFrame({"year" : future_dates.year, 
                                  "month": future_dates.month, 
                                  "day": future_dates.day, 
                                  "day_of_week": future_dates.weekday})

        #ë¯¸ë˜ ë‚ ì§œì— ëŒ€í•œ ë°©ë¬¸ì ìˆ˜ ì˜ˆì¸¡ ìˆ˜í–‰
        future_pred = off_model.predict(future_df)      #ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì˜ˆì¸¡ ìˆ˜í–‰
        future_df["ì˜ˆì¸¡ ë°©ë¬¸ì ìˆ˜"] = future_pred       #ì˜ˆì¸¡ê°’ ì¶”ê°€
        future_df["ë‚ ì§œ"] = future_dates                #ë‚ ì§œ ì¶”ê°€

        #ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”(í–¥í›„ ë°©ë¬¸ì ìˆ˜ ì˜ˆì¸¡)
        st.subheader(f":chart: {select_region}ì˜ ë°©ë¬¸ì ìˆ˜ ì˜ˆì¸¡")
        fig_ml_off, ax_ml_off = plt.subplots(figsize = (9, 6))
        ax_ml_off.plot(future_df.index, future_df["ì˜ˆì¸¡ ë°©ë¬¸ì ìˆ˜"], marker = "o", linestyle = "-", color = "red", label = "ì˜ˆì¸¡ ë°©ë¬¸ì ìˆ˜")
        ax_ml_off.set_title(f"{select_region}ì˜ ë°©ë¬¸ì ìˆ˜ ì˜ˆì¸¡")    #ê·¸ë˜í”„ ì œëª© ì„¤ì •
        ax_ml_off.set_xlabel("ë‚ ì§œ")                                #xì¶• ë ˆì´ë¸” ì„¤ì •
        ax_ml_off.set_ylabel("ë°©ë¬¸ì ìˆ˜")                           #yì¶• ë ˆì´ë¸” ì„¤ì •
        ax_ml_off.legend()                                          #ë²”ë ˆ ì¶”ê°€
        
        #Streamlitì— ê·¸ë˜í”„ ì¶œë ¥
        st.pyplot(fig_ml_off)                                       

        #ë‚ ì§œ í¬ë§· ìˆ˜ì • í›„ ì˜ˆì¸¡ ë°©ë¬¸ì ìˆ˜ ë°ì´í„° ì²˜ë¦¬
        future_df["ë‚ ì§œ"] = pd.to_datetime(future_df["ë‚ ì§œ"]).apply(lambda x: x.replace(day = 1))       #ë‚ ì§œë¥¼ í•´ë‹¹ ì›”ì˜ 1ì¼ë¡œ ì„¤ì •
        future_df["ë‚ ì§œ"] = future_df["ë‚ ì§œ"] + pd.DateOffset(months = 1)                               #ì˜ˆì¸¡ ì›”ì„ ë‹¤ìŒ ë‹¬ë¡œ ì¡°ì •
        future_df["ì˜ˆì¸¡ ë°©ë¬¸ì ìˆ˜"] = future_df["ì˜ˆì¸¡ ë°©ë¬¸ì ìˆ˜"].astype(int).astype(str) + "ëª…"        #ë°©ë¬¸ì ìˆ˜ë¥¼ ì •ìˆ˜ë¡œ ë³€í™˜ í›„ ë¬¸ìì—´ë¡œ ì²˜ë¦¬

        #í–¥í›„ 12ê°œì›”ì˜ ì˜ˆì¸¡ ê²°ê³¼ ì¶œë ¥
        st.subheader(":chart: í–¥í›„ 12ê°œì›”ì˜ ë°©ë¬¸ì ìˆ˜ ì˜ˆì¸¡")

        #Streamlitì— ì˜ˆì¸¡ ë°ì´í„° ì¶œë ¥
        st.write(future_df[["ë‚ ì§œ", "ì˜ˆì¸¡ ë°©ë¬¸ì ìˆ˜"]])